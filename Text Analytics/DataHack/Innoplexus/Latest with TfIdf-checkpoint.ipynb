{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Innoplexus Online Hiring Hackathon: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://datahack.analyticsvidhya.com/contest/innoplexus-online-hiring-hackathon/\n",
    "- https://www.machinelearningplus.com/nlp/gensim-tutorial/  *Check out this tutorial on gensim*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis for drugs/medicines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nowadays the narrative of a brand is not only built and controlled by the company that owns the brand. For this reason, companies are constantly looking out across Blogs, Forums, and other social media platforms, etc for checking the sentiment for their various products and also competitor products to learn how their brand resonates in the market. This kind of analysis helps them as part of their post-launch market research. This is relevant for a lot of industries including pharma and their drugs.\n",
    " \n",
    "\n",
    "The challenge is that the language used in this type of content is not strictly grammatically correct. Some use sarcasm. Others cover several topics with different sentiments in one post. Other users post comments and reply and thereby indicating his/her sentiment around the topic.\n",
    "\n",
    "Sentiment can be clubbed into 3 major buckets - Positive, Negative and Neutral Sentiments.\n",
    "\n",
    " \n",
    "\n",
    "You are provided with data containing samples of text. This text can contain one or more drug mentions. Each row contains a unique combination of the text and the drug mention. Note that the same text can also have different sentiment for a different drug.\n",
    "\n",
    "Given the text and drug name, the task is to predict the sentiment for texts contained in the test dataset. Given below is an example of text from the dataset:\n",
    "\n",
    " \n",
    "\n",
    "Example:\n",
    "\n",
    "*Stelara is still fairly new to Crohn's treatment. This is why you might not get a lot of replies. I've done some research, but most of the \"time to work\" answers are from Psoriasis boards. For Psoriasis, it seems to be about 4-12 weeks to reach a strong therapeutic level. The good news is, Stelara seems to be getting rave reviews from Crohn's patients. It seems to be the best med to come along since Remicade. I hope you have good success with it. My daughter was diagnosed Feb. 19/07, (13 yrs. old at the time of diagnosis), with Crohn's of the Terminal Illium. Has used Prednisone and Pentasa. Started Imuran (02/09), had an abdominal abscess (12/08). 2cm of Stricture. Started ​Remicade in Feb. 2014, along with 100mgs. of Imuran.*\n",
    "\n",
    "For Stelara the above text is ​positive​ while for Remicade the above text is ​negative​."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TRAIN DATA*  \n",
    "unique_hash - \tUnique ID  \n",
    "text\t    -   text pertaining to the drugs  \n",
    "drug\t    -   drug name for which the sentiment is provided  \n",
    "sentiment\t-   (Target) 0-positive, 1-negative, 2-neutral  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THINGS TO DO FOR IMPROVING MODEL\n",
    "\n",
    "*2 sentiment remove few records  \n",
    "fasttext  \n",
    "drug column...feature add 200, train word 2 vec  \n",
    "random forrest  \n",
    "gbbost  \n",
    "deep learning -lstm  \n",
    "hoole house andrew ng  \n",
    "analysis on sentiment - give weightage....multiply buy 1.5 every weight*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more common imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# languange processing imports\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# preprocessing imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# model for word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "#model for vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#model for splitting of data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#logistic regression algo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#naive bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#svm algo \n",
    "from sklearn import svm\n",
    "\n",
    "# Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# hyperparameter training imports\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# visualization imports\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import base64\n",
    "import io\n",
    "%matplotlib inline\n",
    "sns.set()  # defines the style of the plots to be seaborn style\n",
    "\n",
    "##pretty print\n",
    "import pprint as pp\n",
    "\n",
    "#punctuation strings\n",
    "import string\n",
    "\n",
    "#logging each run of cells\n",
    "#import logging\n",
    "\n",
    "#use multi cores\n",
    "import multiprocessing\n",
    "\n",
    "#calculation of time\n",
    "from time import time\n",
    "\n",
    "#accuracy of model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5279, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
       "      <td>Autoimmune diseases tend to come in clusters. As for Gilenya – if you feel good, don’t think about it, it won’t change anything but waste your time and energy. I’m taking Tysabri and feel amazing, no symptoms (other than dodgy color vision, but I’ve had it since always, so, don’t know) and I don’t know if it will last a month, a year, a decade, ive just decided to enjoy the ride, no point in worrying.</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
       "      <td>I can completely understand why you’d want to try it. But, results reported in lectures don’t always stand up to the scrutiny of peer-review during publication. There so much still to do before this is convincing. I hope that it does work out, I really do. And if you’re aware of and happy with the risks, then that’s great. I just think it’s important to present this in a balanced way, and to understand why we don’t move straight from the first show of promise in an animal study to using drugs on humans. There’s still a lot of animal data to gather, and human data to gather before anyone can tell if it’s safe or effective. I can’t tell you how many times animal studies don’t follow through to humans, but it’s one of the major attrition points in drug development. You’ve been through some of the unpredictability issues with Cladribine/Gilenya, where there was an interaction that wasn’t predicted. But once people try it, the doctors can see patterns and work out what’s going on. Clemastine/metformin is very exciting, and given what you’ve said about your current condition and your personal risk tolerance it makes sense to try it. It definitely wouldn’t be for everyone.</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
       "      <td>Interesting that it only targets S1P-1/5 receptors rather than 1-5 like Fingolimod. Hoping to soon see what the AEs and SAEs were Yes. I'm not sure what this means, exactly:  Quote Nine patients reported serious adverse events (2 mg: 3/29 [10.3%], 1.25 mg: 1/43 [2.3%], 0.5 mg: 4/29 [13.8%], and 0.25 mg: 1/50 [2.0%]; no serious adverse event was reported for more than 1 patient and no new safety signals occurred compared with the BOLD Study. If there were 9 patients reporting SAEs, how can it be stated that \"no serious adverse event was reported for more than 1 patient...\"? Maybe I haven't read this right, or maybe there's a misprint. I'm very pleased that something is being developed for SPMS, and it's encouraging that siponimod doesn't linger for very long in the body.</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
       "      <td>Very interesting, grand merci. Now I wonder where lemtrada and ocrevus sales would go, if they prove anti-cd20 are induction</td>\n",
       "      <td>ocrevus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
       "      <td>Hi everybody, My latest MRI results for Brain and Cervical Cord are in and my next Neurologist appointment is in the next couple of weeks. There’re no new lesions in Brain/Cord and I’ve had no relapses while I was on Gilenya. This was a good sign. But there was one line in the cervical cord review that concerned me. It goes : “Lesions at C2-3 and T2 now show hypointensity on the post gadolinium T1 images only. This could represent artifact or early axonal loss.” That was bothersome to read. What are the kind of symptoms from C2-C3 lesion should I be aware of ? Would it result in change of my DMT ? Thanks.</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0   \n",
       "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4   \n",
       "2  fe809672251f6bd0d986e00380f48d047c7e7b76   \n",
       "3  bd22104dfa9ec80db4099523e03fae7a52735eb6   \n",
       "4  b227688381f9b25e5b65109dd00f7f895e838249   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               text  \\\n",
       "0  Autoimmune diseases tend to come in clusters. As for Gilenya – if you feel good, don’t think about it, it won’t change anything but waste your time and energy. I’m taking Tysabri and feel amazing, no symptoms (other than dodgy color vision, but I’ve had it since always, so, don’t know) and I don’t know if it will last a month, a year, a decade, ive just decided to enjoy the ride, no point in worrying.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "1  I can completely understand why you’d want to try it. But, results reported in lectures don’t always stand up to the scrutiny of peer-review during publication. There so much still to do before this is convincing. I hope that it does work out, I really do. And if you’re aware of and happy with the risks, then that’s great. I just think it’s important to present this in a balanced way, and to understand why we don’t move straight from the first show of promise in an animal study to using drugs on humans. There’s still a lot of animal data to gather, and human data to gather before anyone can tell if it’s safe or effective. I can’t tell you how many times animal studies don’t follow through to humans, but it’s one of the major attrition points in drug development. You’ve been through some of the unpredictability issues with Cladribine/Gilenya, where there was an interaction that wasn’t predicted. But once people try it, the doctors can see patterns and work out what’s going on. Clemastine/metformin is very exciting, and given what you’ve said about your current condition and your personal risk tolerance it makes sense to try it. It definitely wouldn’t be for everyone.   \n",
       "2  Interesting that it only targets S1P-1/5 receptors rather than 1-5 like Fingolimod. Hoping to soon see what the AEs and SAEs were Yes. I'm not sure what this means, exactly:  Quote Nine patients reported serious adverse events (2 mg: 3/29 [10.3%], 1.25 mg: 1/43 [2.3%], 0.5 mg: 4/29 [13.8%], and 0.25 mg: 1/50 [2.0%]; no serious adverse event was reported for more than 1 patient and no new safety signals occurred compared with the BOLD Study. If there were 9 patients reporting SAEs, how can it be stated that \"no serious adverse event was reported for more than 1 patient...\"? Maybe I haven't read this right, or maybe there's a misprint. I'm very pleased that something is being developed for SPMS, and it's encouraging that siponimod doesn't linger for very long in the body.                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "3  Very interesting, grand merci. Now I wonder where lemtrada and ocrevus sales would go, if they prove anti-cd20 are induction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "4  Hi everybody, My latest MRI results for Brain and Cervical Cord are in and my next Neurologist appointment is in the next couple of weeks. There’re no new lesions in Brain/Cord and I’ve had no relapses while I was on Gilenya. This was a good sign. But there was one line in the cervical cord review that concerned me. It goes : “Lesions at C2-3 and T2 now show hypointensity on the post gadolinium T1 images only. This could represent artifact or early axonal loss.” That was bothersome to read. What are the kind of symptoms from C2-C3 lesion should I be aware of ? Would it result in change of my DMT ? Thanks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "         drug  sentiment  \n",
       "0  gilenya     2          \n",
       "1  gilenya     2          \n",
       "2  fingolimod  2          \n",
       "3  ocrevus     2          \n",
       "4  gilenya     1          "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Sentiment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3825\n",
       "1    837 \n",
       "0    617 \n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.drug.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(train_data):\n",
    "    \n",
    "    #convert text to lower-case\n",
    "    train_data['tokenized_text'] = train_data['text'].apply(lambda x:' '.join(x.lower() for x in x.split()))\n",
    "\n",
    "    #remove punctuations, unwanted characters\n",
    "    train_data['tokenized_text_1']= train_data['tokenized_text'].apply(lambda x: \"\".join([char for char in x if char not in string.punctuation]))\n",
    "\n",
    "    #remove numbers\n",
    "    train_data['tokenized_text_2']= train_data['tokenized_text_1'].apply(lambda x: re.sub('[0-9]+', ' ' , x))\n",
    "\n",
    "    #remove stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    train_data['tokenized_text_3']= train_data['tokenized_text_2'].apply(lambda x:' '.join(x for x in x.split() if not x in stop))\n",
    "\n",
    "    #lemmatization\n",
    "    train_data['tokenized_text_4']= train_data['tokenized_text_3'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "#         # remove all single characters\n",
    "#     document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    #create a final text field to work on\n",
    "    train_data['final_text'] = train_data['tokenized_text_4']\n",
    "    \n",
    "text_preprocessing(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(train_data.drug)\n",
    "train_data['drug_label'] = label_encoder.transform(train_data.drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_data[train_data['sentiment'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of document term matrix :  (5279, 13832)\n"
     ]
    }
   ],
   "source": [
    "def vectorization(data):\n",
    "\n",
    "    tf=TfidfVectorizer( min_df=10 \n",
    "                       , max_df=0.7\n",
    "                       , lowercase=True \n",
    "                       , ngram_range=(0, 2) \n",
    "                       , stop_words=stopwords.words('english'))\n",
    "    \n",
    "    tfidf_dtm = tf.fit_transform(data).toarray()\n",
    "    print('Shape of document term matrix : ', tfidf_dtm.shape)\n",
    "    return tfidf_dtm\n",
    "\n",
    "train_data['tfidf'] = list(vectorization(train_data['final_text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l = []\n",
    "for key,value in train_data.iterrows():\n",
    "#     value['w2v_features_final'] = np.append(value['w2v_features'],value['drug_label'])\n",
    "    l.append(np.append(value['tfidf'],value['drug_label']))\n",
    "\n",
    "train_data['tfidf_final'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Classsification of Word2Vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tf_train = np.array(list(map(np.array, train_data['tfidf_final'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4223, 13833)\n",
      "(1056, 13833)\n",
      "(4223,)\n",
      "(1056,)\n"
     ]
    }
   ],
   "source": [
    "label = train_data['sentiment']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(text_tf_train, label, random_state=42 , test_size=0.20)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3055\n",
       "1    662 \n",
       "0    506 \n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initiaize supervised learning models\n",
    "\n",
    "clf_A = svm.SVC(kernel='linear'\n",
    "                , class_weight='balanced'  # penalize\n",
    "                , probability=True)\n",
    "clf_B = LogisticRegression(random_state=42)\n",
    "clf_C = MultinomialNB()\n",
    "\n",
    "#  Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "#  samples_100 is the entire training set i.e. len(y_train)\n",
    "#  samples_10 is 10% of samples_100\n",
    "#  samples_1 is 1% of samples_100\n",
    "\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = int(len(y_train)*10/100)\n",
    "samples_1 = int(len(y_train)/100)\n",
    "\n",
    "#sentiment target names\n",
    "target_names = ['0', '1' , '2' ]\n",
    "\n",
    "print('samples_100 : ', samples_100)\n",
    "print('samples_10  : ', samples_10)\n",
    "print('samples_1   : ', samples_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshrs\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clfr = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(learner, sample_size, X_train, y_train, X_val, y_val): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_val: features validation set\n",
    "       - y_val: income validation set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner.fit(X_train[:sample_size],y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end-start\n",
    "        \n",
    "    # TODO: Get the predictions on the validation set(X_val),\n",
    "    #       then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_val = learner.predict(X_val)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end-start\n",
    "        \n",
    "    #Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_val,predictions_val)\n",
    "    \n",
    "    #classification report for precision, relcall, f1-score\n",
    "    results['f_val'] = classification_report(y_val, predictions_val, target_names=target_names)\n",
    "               \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples in {} time with prediction time {} sec.\".format(learner.__class__.__name__\n",
    "                                                                                , sample_size,results['train_time'] \n",
    "                                                                                , results['pred_time'] ))\n",
    "    print()\n",
    "    print(\"{} Classification Report \".format(learner.__class__.__name__) )\n",
    "    print()\n",
    "    print(results['f_val'] )\n",
    "    print(\"Accuracy : \", results['acc_test'])\n",
    "    print(\"******************************************************************************************************************\")\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for clf in [clf_A]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1 , samples_10, samples_100]):\n",
    "        results[clf_name][i] = train_predict(clf, samples, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC trained on 42 samples in 0.17662692070007324 time with prediction time 2.2165777683258057.\n",
      "\n",
      "SVC Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       111\n",
      "          1       0.00      0.00      0.00       175\n",
      "          2       0.73      1.00      0.84       770\n",
      "\n",
      "avg / total       0.53      0.73      0.61      1056\n",
      "\n",
      "0.7291666666666666\n",
      "******************************************************************************************************************\n",
      "SVC trained on 422 samples in 14.777557134628296 time with prediction time 19.801701307296753.\n",
      "\n",
      "SVC Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.01      0.02       111\n",
      "          1       0.60      0.02      0.03       175\n",
      "          2       0.73      1.00      0.84       770\n",
      "\n",
      "avg / total       0.67      0.73      0.62      1056\n",
      "\n",
      "0.7301136363636364\n",
      "******************************************************************************************************************\n",
      "SVC trained on 4223 samples in 694.9112803936005 time with prediction time 160.65574622154236.\n",
      "\n",
      "SVC Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02       111\n",
      "          1       0.71      0.13      0.21       175\n",
      "          2       0.75      0.99      0.85       770\n",
      "\n",
      "avg / total       0.71      0.74      0.66      1056\n",
      "\n",
      "0.7443181818181818\n",
      "******************************************************************************************************************\n",
      "LogisticRegression trained on 42 samples in 0.028769493103027344 time with prediction time 0.07343459129333496.\n",
      "\n",
      "LogisticRegression Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       111\n",
      "          1       0.00      0.00      0.00       175\n",
      "          2       0.73      1.00      0.84       770\n",
      "\n",
      "avg / total       0.53      0.73      0.61      1056\n",
      "\n",
      "0.7291666666666666\n",
      "******************************************************************************************************************\n",
      "LogisticRegression trained on 422 samples in 0.0928037166595459 time with prediction time 0.05730009078979492.\n",
      "\n",
      "LogisticRegression Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       111\n",
      "          1       0.00      0.00      0.00       175\n",
      "          2       0.73      1.00      0.84       770\n",
      "\n",
      "avg / total       0.53      0.73      0.61      1056\n",
      "\n",
      "0.7291666666666666\n",
      "******************************************************************************************************************\n",
      "LogisticRegression trained on 4223 samples in 1.1284258365631104 time with prediction time 0.06419634819030762.\n",
      "\n",
      "LogisticRegression Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       111\n",
      "          1       0.68      0.07      0.13       175\n",
      "          2       0.74      0.99      0.85       770\n",
      "\n",
      "avg / total       0.65      0.74      0.64      1056\n",
      "\n",
      "0.7367424242424242\n",
      "******************************************************************************************************************\n",
      "MultinomialNB trained on 42 samples in 0.012639522552490234 time with prediction time 0.06619715690612793.\n",
      "\n",
      "MultinomialNB Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       111\n",
      "          1       0.00      0.00      0.00       175\n",
      "          2       0.73      1.00      0.84       770\n",
      "\n",
      "avg / total       0.53      0.73      0.61      1056\n",
      "\n",
      "0.7291666666666666\n",
      "******************************************************************************************************************\n",
      "MultinomialNB trained on 422 samples in 0.03650474548339844 time with prediction time 0.07226872444152832.\n",
      "\n",
      "MultinomialNB Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       111\n",
      "          1       0.00      0.00      0.00       175\n",
      "          2       0.73      0.99      0.84       770\n",
      "\n",
      "avg / total       0.53      0.72      0.61      1056\n",
      "\n",
      "0.7244318181818182\n",
      "******************************************************************************************************************\n",
      "MultinomialNB trained on 4223 samples in 0.3109714984893799 time with prediction time 0.07036519050598145.\n",
      "\n",
      "MultinomialNB Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.03      0.05       111\n",
      "          1       0.29      0.03      0.06       175\n",
      "          2       0.73      0.96      0.83       770\n",
      "\n",
      "avg / total       0.60      0.71      0.62      1056\n",
      "\n",
      "0.7102272727272727\n",
      "******************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for clf in [clf_A,clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1 , samples_10, samples_100]):\n",
    "        results[clf_name][i] = train_predict(clf, samples, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshrs\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier trained on 42 samples in 0.24901795387268066 time with prediction time 0.18123745918273926.\n",
      "\n",
      "RandomForestClassifier Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       111\n",
      "          1       0.00      0.00      0.00       175\n",
      "          2       0.73      1.00      0.84       770\n",
      "\n",
      "avg / total       0.53      0.73      0.61      1056\n",
      "\n",
      "0.7291666666666666\n",
      "******************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshrs\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier trained on 422 samples in 0.415241003036499 time with prediction time 0.1688692569732666.\n",
      "\n",
      "RandomForestClassifier Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       111\n",
      "          1       0.00      0.00      0.00       175\n",
      "          2       0.73      1.00      0.84       770\n",
      "\n",
      "avg / total       0.53      0.73      0.61      1056\n",
      "\n",
      "0.7291666666666666\n",
      "******************************************************************************************************************\n",
      "RandomForestClassifier trained on 4223 samples in 2.8398873805999756 time with prediction time 0.17096734046936035.\n",
      "\n",
      "RandomForestClassifier Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       111\n",
      "          1       0.00      0.00      0.00       175\n",
      "          2       0.73      1.00      0.84       770\n",
      "\n",
      "avg / total       0.53      0.73      0.61      1056\n",
      "\n",
      "0.7291666666666666\n",
      "******************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshrs\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for clf in [clfr]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1 , samples_10, samples_100]):\n",
    "        results[clf_name][i] = train_predict(clf, samples, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "### Choosen one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   15.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 16.641916513442993 sec: \n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   15.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV trained on 4223 samples in 15.868688344955444 time with prediction time 0.000997781753540039.\n",
      "\n",
      "GridSearchCV Classification Report \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       111\n",
      "          1       0.67      0.10      0.18       175\n",
      "          2       0.74      0.99      0.85       770\n",
      "\n",
      "avg / total       0.65      0.74      0.65      1056\n",
      "\n",
      "0.7395833333333334\n",
      "******************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshrs\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_time': 15.868688344955444, 'pred_time': 0.000997781753540039, 'acc_test': 0.7395833333333334, 'f_val': '             precision    recall  f1-score   support\\n\\n          0       0.00      0.00      0.00       111\\n          1       0.67      0.10      0.18       175\\n          2       0.74      0.99      0.85       770\\n\\navg / total       0.65      0.74      0.65      1056\\n'}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # define parameters for grid search and train the model\n",
    "\n",
    "param_grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "logreg_cv=GridSearchCV(logreg,param_grid,cv=5, n_jobs=-1 , verbose=True)\n",
    "\n",
    "start = time() # Get start time\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "end = time() # Get end time\n",
    "\n",
    "print(\"Training time {} sec: \". format(end-start))\n",
    "\n",
    "train_predict(logreg_cv, samples_100, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on full train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer_model = clf_A.fit(text_tf_train,train_data['sentiment'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prediction on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2924, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
       "      <td>256 (previously stable on natalizumab), with 55% switching to fingolimod</td>\n",
       "      <td>fingolimod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  9e9a8166b84114aca147bf409f6f956635034c08   \n",
       "\n",
       "                                                                       text  \\\n",
       "0  256 (previously stable on natalizumab), with 55% switching to fingolimod   \n",
       "\n",
       "         drug  \n",
       "0  fingolimod  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "print(test_data.shape)\n",
    "test_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessing(test_data)\n",
    "#  \n",
    "#     tokenize_text_to_words(df)\n",
    "#     remove_stopwords(df)\n",
    "#     stem_words(df)\n",
    "#     document_to_bow(df)\n",
    "#  \n",
    "\n",
    "#w2v_preprocessing(test_data)\n",
    "\n",
    "#   convert to lower case\n",
    "#   split texts into individual sentences\n",
    "#   remove punctuations`\n",
    "#   tokenize sentences    \n",
    "#   remove unwanted characters\n",
    "#   remove empty lists\n",
    "#   copy to create a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>tokenized_text_1</th>\n",
       "      <th>tokenized_text_2</th>\n",
       "      <th>tokenized_text_3</th>\n",
       "      <th>tokenized_text_4</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
       "      <td>256 (previously stable on natalizumab), with 55% switching to fingolimod</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>256 (previously stable on natalizumab), with 55% switching to fingolimod</td>\n",
       "      <td>256 previously stable on natalizumab with 55 switching to fingolimod</td>\n",
       "      <td>previously stable on natalizumab with   switching to fingolimod</td>\n",
       "      <td>previously stable natalizumab switching fingolimod</td>\n",
       "      <td>previously stable natalizumab switching fingolimod</td>\n",
       "      <td>previously stable natalizumab switching fingolimod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  9e9a8166b84114aca147bf409f6f956635034c08   \n",
       "\n",
       "                                                                       text  \\\n",
       "0  256 (previously stable on natalizumab), with 55% switching to fingolimod   \n",
       "\n",
       "         drug  \\\n",
       "0  fingolimod   \n",
       "\n",
       "                                                             tokenized_text  \\\n",
       "0  256 (previously stable on natalizumab), with 55% switching to fingolimod   \n",
       "\n",
       "                                                       tokenized_text_1  \\\n",
       "0  256 previously stable on natalizumab with 55 switching to fingolimod   \n",
       "\n",
       "                                                    tokenized_text_2  \\\n",
       "0    previously stable on natalizumab with   switching to fingolimod   \n",
       "\n",
       "                                     tokenized_text_3  \\\n",
       "0  previously stable natalizumab switching fingolimod   \n",
       "\n",
       "                                     tokenized_text_4  \\\n",
       "0  previously stable natalizumab switching fingolimod   \n",
       "\n",
       "                                           final_text  \n",
       "0  previously stable natalizumab switching fingolimod  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tf_test= tf.transform(test_data['final_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2924x13832 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 396152 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a numpy array for prediction\n",
    "\n",
    "# X_test_w2v = np.array(list(map(np.array, test_data.w2v_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict from the choosen model\n",
    "\n",
    "submission_predictions = trainer_model.predict(text_tf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2924, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  sentiment\n",
       "0  9e9a8166b84114aca147bf409f6f956635034c08  0        \n",
       "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a  0        \n",
       "2  50b6d851bcff4f35afe354937949e9948975adf7  0        \n",
       "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae  0        \n",
       "4  8b37d169dee5bdae27060949242fb54feb6a7f7f  0        "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "print(sample_sub.shape)\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           unique_hash\n",
       "sentiment             \n",
       "0          8          \n",
       "1          66         \n",
       "2          2850       "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"unique_hash\": test_data[\"unique_hash\"],\n",
    "        \"sentiment\": submission_predictions\n",
    "    })\n",
    "submission.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission2.csv', index=False)\n",
    "#0.58289"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
